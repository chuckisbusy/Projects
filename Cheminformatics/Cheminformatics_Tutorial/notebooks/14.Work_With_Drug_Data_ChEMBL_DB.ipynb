{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463e70b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Working With Drug Data From the ChEMBL Database\n",
    "\n",
    "When working on drug discovery projects, it's handy to have access to a set of chemical structures and associated data for marketed drugs. If you're considering introducing new functionality, someone invariably asks whether that functionality has been used in a marketed drug. It's also helpful to compare the properties of a new compound or compounds to those of marketed drugs. Early in my career, I remember a new medicinal chemist asking Josh Boger, the founder of Vertex Pharmaceuticals, what they should do on their first day of work. Boger responded, \"read the Merck Index, so you can see what a drug is supposed to look like\". Recently a [few](https://pubs.acs.org/doi/10.1021/acs.jmedchem.8b00686) [papers](https://www.nature.com/articles/s41570-022-00451-0) have been published showing how the properties of drugs have changed over time. I thought it might be helpful to create a notebook showing how to extract and clean drug data from ChEMBL and use it to perform a similar analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370dabe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Overview\n",
    "\n",
    "In this notebook we'll perform the following steps.\n",
    "\n",
    "1. Download the ChEMBL database\n",
    "2. Query ChEMBL for drug data\n",
    "3. Remove duplicates from the ChEMBL data\n",
    "4. Divide the ChEMBL data into three groups based on the first approval date, before 1997, 1997-2017, after 2017\n",
    "5. Compare the molecular weight and calculated logp distributions for the three groups and determine if the differences between groups are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d002a56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import chembl_downloader\n",
    "import pandas as pd\n",
    "import scikit_posthocs as sp\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.rdBase import BlockLogs\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be133eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Enable progress bars in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "496a50a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a355d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Download the ChEMBL database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33799c85",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We begin by using the awesome [ChEMBL downloader](https://github.com/cthoyt/chembl-downloader) by Charles Tapley Hoyt to download the latest version of the ChEMBL database.  On my laptop, this took 7 minutes and consumed 27GB of disk space. The ChEMBL downloader not only makes it easy to download the database, it also allows you to submit queries and returns the results as a Pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260f49f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f1bdb205b848e9965ee83aecbb317e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading chembl_35_sqlite.tar.gz: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = chembl_downloader.download_extract_sqlite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709d940",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a590483",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define SQL to extract drug data from ChEMBL. It would probably be useful to explain the query below.  We're joining three tables:\n",
    "- molecule_dictionary - Table storing a non-redundant list of curated compounds for ChEMBL (includes preclinical compounds, drugs and clinical candidate drugs) and some associated attributes.\n",
    "- compound_structures - Table storing various structure representations (e.g., Molfile, InChI) for each compound\n",
    "- compound properties - Table storing calculated physicochemical properties for compounds, now calculated with RDKit and ChemAxon software (note all but FULL_MWT and FULL_MOLFORMULA are calculated on the parent structure)\n",
    "\n",
    "\n",
    "We select records where\n",
    "- max_phase = 4 (approved drugs)\n",
    "- molecule_type = Small molecule\n",
    "- molecular weight is between 200 and 1000\n",
    "\n",
    "The group by ensures that we have one record for each canonical_smiles, molregno pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c76d6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select cs.canonical_smiles, cs.molregno, pref_name, first_approval, dosed_ingredient, oral, parenteral, topical,\n",
    "       black_box_warning, first_in_class from molecule_dictionary md\n",
    "join compound_structures cs on cs.molregno = md.molregno\n",
    "join compound_properties cp on md.molregno = cp.molregno\n",
    "where max_phase = 4 and molecule_type = 'Small molecule'\n",
    "and cp.full_mwt > 200 and cp.full_mwt < 1000\n",
    "group by cs.canonical_smiles, cs.molregno\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f60c8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = chembl_downloader.query(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d58fab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3adcf9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Remove duplicates from the ChEMBL data\n",
    "\n",
    "Several drugs are in ChEMBL multiple times as different salt forms.  To simplify our analysis, we'd like to only have each drug represented once.  We can use the MolStandardize functionality in the RDKit to remove salts and add another column with the standardized SMILES (std_smiles).  I used the example code below from the bitsilla blog to standardize the SMILES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46745ec5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Borrowed from https://bitsilla.com/blog/2021/06/standardizing-a-molecule-using-rdkit/\n",
    "def standardize(smiles):\n",
    "    # follows the steps in\n",
    "    # https://github.com/greglandrum/RSC_OpenScience_Standardization_202104/blob/main/MolStandardize%20pieces.ipynb\n",
    "    # as described **excellently** (by Greg) in\n",
    "    # https://www.youtube.com/watch?v=eWTApNX8dJQ\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # removeHs, disconnect metal atoms, normalize the molecule, reionize the molecule\n",
    "    clean_mol = rdMolStandardize.Cleanup(mol)\n",
    "\n",
    "    # if many fragments, get the \"parent\" (the actual mol we are interested in) \n",
    "    parent_clean_mol = rdMolStandardize.FragmentParent(clean_mol)\n",
    "\n",
    "    # try to neutralize molecule\n",
    "    uncharger = rdMolStandardize.Uncharger()  # annoying, but necessary as no convenience method exists\n",
    "    uncharged_parent_clean_mol = uncharger.uncharge(parent_clean_mol)\n",
    "\n",
    "    # note that no attempt is made at reionization at this step\n",
    "    # nor at ionization at some pH (rdkit has no pKa caculator)\n",
    "    # the main aim to represent all molecules from different sources\n",
    "    # in a (single) standard way, for use in ML, catalogue, etc.\n",
    "\n",
    "    te = rdMolStandardize.TautomerEnumerator()  # idem\n",
    "    taut_uncharged_parent_clean_mol = te.Canonicalize(uncharged_parent_clean_mol)\n",
    "\n",
    "    return Chem.MolToSmiles(taut_uncharged_parent_clean_mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c434fd5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code below performs the standardization and creates a new column.  Note the use of [BlockLogs](https://rdkit.org/docs/source/rdkit.rdBase.html).  The standardizer has a lot of logging messages that I prefer to ignore.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82094e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with BlockLogs():\n",
    "    df['std_smiles'] = df.canonical_smiles.progress_apply(standardize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c354e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Drop any rows that don't have a first_approval year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3363592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ok = df.dropna(subset=[\"first_approval\"]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd9c24a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The **first_approval** field comes over from ChEMBL as a floating point number.  This bugs me, so I'll convert it to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed615eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ok.first_approval = df_ok.first_approval.astype(int)\n",
    "df_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd595a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look a structures that occur multiple times.  The first one is citrate. This is an odd case where we have things like sodium citrate where the salt is larger than the parent.  There aren't a lot of these and I don't find them interesting so I'm ignoring them.  The second example, which occurs six times is more interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d1176",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_freq = uru.value_counts_df(df_ok, \"std_smiles\")\n",
    "df_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a11d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we take a look at this one, we see various forms of penicillin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094c4ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query_smi = df_freq.std_smiles.values[1]\n",
    "print(query_smi)\n",
    "df_ok.query(\"std_smiles == @query_smi\").sort_values(\"first_approval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a13cb5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's remove the duplicate structures. To do this, we sort by **first_approval** then remove duplicate **std_smiles**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba3857",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ok_nodupe = df_ok.sort_values(\"first_approval\").drop_duplicates(\"std_smiles\").copy()\n",
    "len(df_ok), len(df_ok_nodupe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffbd52a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, let's limit our analysis to oral drugs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2cba4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_oral_ok_nodupe = df_ok_nodupe.query(\"oral == 1\").copy()\n",
    "len(df_oral_ok_nodupe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50a0a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There still may be duplicates that are the same structure with different charge states.  One way to handle this is to generate an InChI for each structure and remove the charge layer.  In this way, the charged and uncharged versions will have the same InChI string. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a2c09f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define a function to generate an InChI without the charge field.  This is a bit of a hack.  I should probably be passing the \"nochg\" option to Chem.MolToInchi but I can't figure out how to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc8df7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def smi_to_inchi_nochg(smi):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    inchi = Chem.MolToInchi(mol)\n",
    "    return re.sub(\"/p\\+[0-9]+\", \"\", inchi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342397c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To test our function we'll generate InChi strings for the neutral and protonated forms of propylamine.  We can then check to see if the InChi strings are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339617f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_chg_inchi = smi_to_inchi_nochg(\"CCCN\")\n",
    "chg_inchi = smi_to_inchi_nochg(\"CCC[NH3+]\")\n",
    "no_chg_inchi, chg_inchi, chg_inchi == no_chg_inchi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eace57e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we'll apply this function to all the structures in our dataframe. As above, I'm using **BlockLogs** to ignore the logging messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f927c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with BlockLogs():\n",
    "    df_oral_ok_nodupe['inchi'] = df_oral_ok_nodupe.std_smiles.apply(smi_to_inchi_nochg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f55005",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see if we have any InChI duplicates.  We can use the function **value_counts_df** from the [useful_rdkit_utils](https://github.com/PatWalters/useful_rdkit_utils) package to convert the results of the Pandas value_counts method to a nicely formatted dataframe.  It looks like there's only one example with two different charge states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c0733",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_dupe_inchi = uru.value_counts_df(df_oral_ok_nodupe, \"inchi\")\n",
    "df_dupe_inchi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbab18",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a closer look at this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef4572",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inchi_val = df_dupe_inchi.inchi.values[0]\n",
    "dupe_inchi_df = df_oral_ok_nodupe.query(\"inchi == @inchi_val\")\n",
    "dupe_inchi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827acd3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dupe_inchi_df.std_smiles.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11489e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dupe_mol_list = [Chem.MolFromSmiles(x) for x in dupe_inchi_df.std_smiles]\n",
    "MolsToGridImage(dupe_mol_list, useSVG=True, subImgSize=(350, 350))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5c9e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to clean things up a bit, we can drop the duplicate record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b90bb8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_final_drug = df_oral_ok_nodupe.sort_values(\"first_approval\").drop_duplicates(\"inchi\").copy()\n",
    "len(df_final_drug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f9d8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Divide the ChEMBL data into three groups, before 1997, 1997-2017, after 2017\n",
    "\n",
    "Now that we have a clean datset, we can do some analysis.  We'll start dividing the data into three sets based on the first approval year.  To do this we'll use the criteria defined in a 2023 paper by [Hartung, Webb, and Crespo](https://www.nature.com/articles/s41570-022-00451-0). Note how the Pandas cut function makes it easy to bin the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edb73d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_final_drug['era'] = pd.cut(df_final_drug.first_approval, [0, 1996, 2017, 5000],\n",
    "                              labels=[\"before 1997\", \"1997-2017\", \"after 2017\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfb80e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_final_drug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea847e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Compare the molecular weight and calculated logp distributions for the three groups, and determine if the differences between groups are statistically significant.\n",
    "Now let's calculate the parameters that define Lipinski's Rule of 5.  Fortunately, the [useful_rdkit_utils](https://github.com/PatWalters/useful_rdkit_utils) package has a convenience function to make this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884beb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ro5_calc = uru.Ro5Calculator()\n",
    "df_final_drug[ro5_calc.names] = df_final_drug.std_smiles.apply(ro5_calc.calc_smiles).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc449e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_final_drug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a17db",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With that data in hand, we can make boxplots to show the molecular weight distributions over the three time periods in question.  Based on the boxplots, it appears that there is a trend toward increasing molecular weight over time.  However, we also want to look at whether there is a statistically signficant difference between the distributions. We'll look at this below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fc6fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"era\", y=\"MolWt\", data=df_final_drug)\n",
    "ax.set_xlabel(\"Era\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d476ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As mentioned above, we want to evaluate whether the molecular weight distributions above are different.  When working with normally distributed data, we would use something like Student's t-test to compare two distributions.  Since the distributions we're dealing with are not normally distributed we'll use the non-parametric Wilcoxon Rank Sum Test.  We're dealing with three distributions, so we need to correct the p-value to account for multiple comparisons.  Fortunately for us, there's the **scikit-posthocs** Python package to do the heavy lifting.  For more on multiple comparisons and post-hoc tests, please see this Practical Cheminformatics blog post. Looking at the plot below, we see that we can invalidate the null hypothesis that the means of the distributions are the same with at least p < 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d39bc3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (8, 6)}, font_scale=1.5)\n",
    "pc = sp.posthoc_mannwhitney(df_final_drug, val_col=\"MolWt\", group_col=\"era\", p_adjust='holm')\n",
    "heatmap_args = {'linewidths': 0.25, 'linecolor': '0.5', 'clip_on': False, 'square': True,\n",
    "                'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]}\n",
    "_ = sp.sign_plot(pc, **heatmap_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b76348",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Following the pattern above, we can look do the same analysis with the calculated LogP.  In this case, the two distributions on the right look similar.  Let's look at the statistics and see if they are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa66ebc8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"era\", y=\"LogP\", data=df_final_drug)\n",
    "ax.set_xlabel(\"Era\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aad9ff7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Again, we'll use scikit-posthocs to create a heatmap.  In this case we can see that for \"1997-2017\" and \"after 2017\" sets, we cannot invalidate the null hypothesis that that distributions are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2694837",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (8, 6)}, font_scale=1.5)\n",
    "pc = sp.posthoc_mannwhitney(df_final_drug, val_col=\"LogP\", group_col=\"era\", p_adjust='holm')\n",
    "heatmap_args = {'linewidths': 0.25, 'linecolor': '0.5', 'clip_on': False, 'square': True,\n",
    "                'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]}\n",
    "_ = sp.sign_plot(pc, **heatmap_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacfcbb6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Acknowledgements\n",
    "\n",
    "I'd like to thank Emanuele Perola for motivating this notebook and Brian Kelley and Joann Prescott-Roy for helpful discussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873d013",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
